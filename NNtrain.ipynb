{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NOTAS\n",
    "- BOW con sklearn: inviable porque me elimina las fechas.\n",
    "- Analzador con stanza : RuntimeError: CUDA error: no kernel image is available for execution on the device.\n",
    "- Bag of word de todo saldria un diccionario enorme y con un costo computacional inmenso.\n",
    "- Al tener más lugares donde tener que analizar el contexto, la red neuronal se vuelve más volatil.\n",
    "- Por NLP pasa algo similiar a lo que pasa en el punto anterior, al tener más texto, tenemos más taggs y el analisis del contexto se vuelve muy complejo, ademas se suma la terminologia, las formulas medicas y las abreviaciones, las cuales los programas de taggeo para el POS se les hace imposible clasificar."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'!\"#%&\\'()*+,-./:;<?@[\\\\]^_`{|}~'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "#nltk.download()\n",
    "import stanza \n",
    "import spacy_stanza\n",
    "import string\n",
    "#stanza.download('es')\n",
    "import spacy\n",
    "#!python3 -m spacy download es_core_news_sm\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "import pdf_to_txt_3\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer() \n",
    "string.punctuation.replace(\"$\",'').replace(\"=>\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para quitar los acentos \n",
    "def normalize(s):\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "    )\n",
    "    for a, b in replacements:\n",
    "        s = s.replace(a, b)\n",
    "    return s\n",
    "\n",
    "# funcion para permanecer las mayusculas de las secciones\n",
    "def agg_mayusculas(s):\n",
    "    replacements =(\n",
    "            ('motivo de consulta','MOTIVO DE CONSULTA'),\n",
    "            ('enfermedad actual','ENFERMEDAD ACTUAL'),\n",
    "            ('examen físico','EXAMEN FÍSICO'),\n",
    "            ('análisis','ANÁLISIS'),\n",
    "            ('plan y manejo','PLAN Y MANEJO'),\n",
    "            ('diagnóstico','DIAGNÓSTICO'),\n",
    "            ('ordenes','ORDENES'),\n",
    "            ('órdenes','ÓRDENES'),\n",
    "            ('interconsultas','INTERCONSULTAS'),\n",
    "            ('notas enfermeria','NOTAS ENFERMERIA'),\n",
    "            ('formula médica','FORMULA MÉDICA'),\n",
    "            ('formatos','FORMATOS'),\n",
    "            ('recomendaciones','RECOMENDACIONES'),\n",
    "            ('nota de ingreso','NOTA DE INGRESO'),\n",
    "            ('observaciones','OBSERVACIONES')\n",
    "            )\n",
    "\n",
    "    for a, b in replacements:\n",
    "        s = s.replace(a, b) \n",
    "    return s\n",
    "\n",
    "# funcion para pasar de texto a numeros \n",
    "def translate(text,word_index):\n",
    "    ''' Esta función usa el diccionario de la bolsa de palabras\n",
    "        Para transformar un texto en una lista de numeros\n",
    "        texto -> numeros\n",
    "        \n",
    "        -----------\n",
    "        Parametros:\n",
    "        -----------\n",
    "        - text (string) : el string del texto a traducir\n",
    "         '''\n",
    "    text = text.split(\" \")\n",
    "    return [word_index.get(palabra,2) for palabra in text]\n",
    "\n",
    "# funcion para pasar de numeros a texto\n",
    "def traductor(list_number,reverse_word_index):\n",
    "    ''' Esta función usa el diccionario de la bolsa de palabras\n",
    "        Para transformar un texto en una lista de numeros\n",
    "        numeros -> texto\n",
    "        \n",
    "        -----------\n",
    "        Parametros:\n",
    "        -----------\n",
    "        - text (string) : el string del texto a traducir\n",
    "         '''\n",
    "    lista = [reverse_word_index.get(numero,'?') for numero in list_number]\n",
    "    return ' '.join(lista).replace('<PAD>','')\n",
    "\n",
    "\n",
    "\n",
    "# funcion para crear la bolsa de palabras\n",
    "def bag(super_string):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cv = CountVectorizer() \n",
    "    words = super_string.split(\" \")\n",
    "    Bag = cv.fit(words)\n",
    "    #print(sorted(Bag.vocabulary_.items()))\n",
    "    # ahroa haremos un diccionario con las palabras\n",
    "    word_index = {k:(v+len(mayusculas)+3) for k,v in sorted(Bag.vocabulary_.items())}\n",
    "    # El diccionario lo empezamos en v+3 \n",
    "    # para que las 4 primeras sean caracteres especiales\n",
    "\n",
    "    # Los caracteres especiales serán \n",
    "    word_index[\"<PAD>\"] = 0\n",
    "    word_index[\"<START>\"] = 1\n",
    "    word_index[\"<UNK>\"] = 2\n",
    "    word_index[\"<UNUSED>\"] = 3\n",
    "    for mayuscula in range(len(mayusculas)):\n",
    "        word_index[mayusculas[mayuscula]] = mayuscula+3\n",
    "\n",
    "    reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "    return word_index, reverse_word_index\n",
    "\n",
    "\n",
    "def def_len(seccion):\n",
    "    seccion = tf.keras.preprocessing.sequence.pad_sequences(seccion, value= word_index[\"<PAD>\"],padding=\"post\", maxlen= 5000 )\n",
    "    return seccion\n",
    "    \n",
    "\n",
    "\n",
    "# creamos función para remover los signos de puntuacion\n",
    "def remove_punctuation(text):\n",
    "    puntc = string.punctuation.replace(\"$\",'').replace(\"=>\",'') + \"“\"\n",
    "    text_input = nltk.tokenize.word_tokenize(text)\n",
    "    text_output = [text for text in text_input if text not in puntc]\n",
    "    return ' '.join(text_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lista de las mayusculas para agregar en el diccionario de la bolsa de palabras\n",
    "mayusculas = ['ACTUAL', 'ANÁLISIS', 'CONSULTA', 'DE', 'DIAGNÓSTICO', 'ENFERMEDAD', 'ENFERMERIA', 'EXAMEN', 'FORMATOS', 'FORMULA', 'FÍSICO', 'INGRESO', 'INTERCONSULTAS', 'MANEJO', 'MOTIVO', 'MÉDICA', 'NOTA', 'NOTAS', 'OBSERVACIONES', 'ORDENES', 'PLAN', 'RECOMENDACIONES', 'Y', 'ÓRDENES']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SuperString para Bag_of_words\n",
    "super_string = '' # donde agregaremos el texto de todos los pdf\n",
    "secciones = [] # donde agregaremos todas las secciones \n",
    "\n",
    "# lista de las secciones tanto en letras como numericas\n",
    "\n",
    "# 1\n",
    "motivo_consulta = []\n",
    "motivo_consulta_n = []\n",
    "\n",
    "#2\n",
    "enfermedad_actual = []\n",
    "enfermedad_actual_n = []\n",
    "\n",
    "#3\n",
    "examen_fisico = []\n",
    "examen_fisico_n = []\n",
    "\n",
    "#4\n",
    "analisis = []\n",
    "analisis_n = []\n",
    "\n",
    "#5\n",
    "plan_manejo = []\n",
    "plan_manejo_n = []\n",
    "\n",
    "#6\n",
    "diagnostico = []\n",
    "diagnostico_n = []\n",
    "\n",
    "#7\n",
    "ordenes = []\n",
    "ordenes_n = []\n",
    "\n",
    "#8\n",
    "interconsultas = []\n",
    "interconsultas_n = []\n",
    "\n",
    "#9\n",
    "notas_enfermeria = []\n",
    "notas_enfermeria_n = []\n",
    "\n",
    "#10\n",
    "formula_medica = []\n",
    "formula_medica_n = []\n",
    "\n",
    "#11\n",
    "formatos = []\n",
    "formatos_n = []\n",
    "\n",
    "#12\n",
    "recomendaciones = []\n",
    "recomendaciones_n = []\n",
    "\n",
    "#13\n",
    "notas_ingreso = []\n",
    "notas_ingreso_n = []\n",
    "\n",
    "#14\n",
    "observaciones = []\n",
    "observaciones_n = []\n",
    "\n",
    "#15\n",
    "otros = []\n",
    "otros_n = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesamiento general\n",
    "textos = glob.glob('*.txt')\n",
    "for texto in textos:\n",
    "    with open(texto,'r') as file:\n",
    "        paciente = file.read()\n",
    "        paciente = paciente.lower().replace(\"\\n\",\" \") # quitamos los \"\\n\"\n",
    "        paciente = agg_mayusculas(paciente) # agregamos las mayusculas de las secciones\n",
    "        paciente = normalize(paciente) # quitamos los acentos de la data\n",
    "        paciente = remove_punctuation(paciente)\n",
    "        super_string = super_string + '   \\n   '+paciente  # agregamos parte al super_string\n",
    "        partes = paciente.split('$ $') # separamos por secciones \n",
    "        for parte in partes:\n",
    "            secciones.append(parte) # general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index , reverse_word_index = bag(super_string) # generamos el dicionario de palabras y el inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "secciones_n = [] # creamos una lista de todas las secciones en numero \n",
    "for sec in secciones:\n",
    "    seccion = translate(sec,word_index) # traducimos a numeros\n",
    "    secciones_n.append(seccion) # agregamosa en la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "secciones_n = tf.keras.preprocessing.sequence.pad_sequences(secciones_n,\n",
    "                                                     value= word_index[\"<PAD>\"],\n",
    "                                                     padding=\"post\",\n",
    "                                                     maxlen= 5000 )\n",
    "# definimos un len maximo para la lista de palabras numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos cada seccion a su lista en palabras y numerica correspondiente\n",
    "for seccion in secciones:\n",
    "    if 'MOTIVO DE CONSULTA' in seccion:\n",
    "        motivo_consulta.append(seccion)\n",
    "        motivo_consulta_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'ENFERMEDAD ACTUAL' in seccion:\n",
    "        enfermedad_actual.append(seccion)\n",
    "        enfermedad_actual_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'EXAMEN FÍSICO' in seccion:\n",
    "        examen_fisico.append(seccion)\n",
    "        examen_fisico_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'ANÁLISIS' in seccion:\n",
    "        analisis.append(seccion)\n",
    "        analisis_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'PLAN Y MANEJO' in seccion:\n",
    "        plan_manejo.append(seccion)\n",
    "        plan_manejo_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'DIAGNÓSTICO' in seccion:\n",
    "        diagnostico.append(seccion)\n",
    "        diagnostico_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif ('ORDENES' or 'ÓRDENES') in seccion:\n",
    "        ordenes.append(seccion)\n",
    "        ordenes_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'INTERCONSULTAS' in seccion:\n",
    "        interconsultas.append(seccion)\n",
    "        interconsultas_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'NOTAS ENFERMERIA' in seccion:\n",
    "        notas_enfermeria.append(seccion)\n",
    "        notas_enfermeria_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'FORMULA MÉDICA' in seccion:\n",
    "        formula_medica.append(seccion)\n",
    "        formula_medica_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'FORMATOS' in seccion:\n",
    "        formatos.append(seccion)\n",
    "        formatos_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'RECOMENDACIONES' in seccion:\n",
    "        recomendaciones.append(seccion)\n",
    "        recomendaciones_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'NOTA DE INGRESO' in seccion:\n",
    "        notas_ingreso.append(seccion)\n",
    "        notas_ingreso_n.append(translate(seccion,word_index))\n",
    "\n",
    "    elif 'OBSERVACIONES' in seccion:\n",
    "        observaciones.append(seccion)\n",
    "        observaciones_n.append(translate(seccion,word_index))\n",
    "\n",
    "    else:\n",
    "        otros.append(secciones)\n",
    "        otros_n.append(translate(seccion,word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos un len maximo para la lista de palabras numerica para cada seccion \n",
    "\n",
    "#1\n",
    "motivo_consulta_n = def_len(motivo_consulta_n)\n",
    "\n",
    "#2\n",
    "enfermedad_actual_n = def_len(enfermedad_actual_n)\n",
    "\n",
    "#3\n",
    "examen_fisico_n = def_len(examen_fisico_n)\n",
    "\n",
    "#4\n",
    "analisis_n = def_len(analisis_n)\n",
    "\n",
    "#5\n",
    "plan_manejo_n = def_len(plan_manejo_n)\n",
    "\n",
    "#6\n",
    "diagnostico_n = def_len(diagnostico_n)\n",
    "\n",
    "#7\n",
    "ordenes_n = def_len(ordenes_n)\n",
    "\n",
    "#8\n",
    "notas_enfermeria_n = def_len(notas_enfermeria_n)\n",
    "\n",
    "#9\n",
    "formula_medica_n = def_len(formula_medica_n)\n",
    "\n",
    "#10\n",
    "formatos_n = def_len(formatos_n)\n",
    "\n",
    "#11\n",
    "recomendaciones_n = def_len(recomendaciones_n)\n",
    "\n",
    "#12\n",
    "notas_ingreso_n = def_len(notas_ingreso_n)\n",
    "\n",
    "#13\n",
    "observaciones_n = def_len(observaciones_n)\n",
    "\n",
    "#14\n",
    "otros_n = def_len(otros_n)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  2  26 414 834 720 853 332 429   2 799 975 575 245 982 787   2   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n \n \n<UNK> ÓRDENES de procedimientos no quirurgico cantidad descripcion <UNK> pl tin ica alta toxic pendiente <UNK>                                  \n \n \n ÓRDENES de procedimientos no quirurgico cantidad descripcion 1 pl tin ica alta toxic pendiente \n \n['ÓRDENES', 'de', 'procedimientos', 'no', 'quirurgico', 'cantidad', 'descripcion', '1', 'pl', 'tin', 'ica', 'alta', 'toxic', 'pendiente']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4e1d94248196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(\\d+/\\d+/\\d+)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecciones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# verificamos que este de forma correcta \n",
    "i = 4\n",
    "print(secciones_n[i][:50])\n",
    "print(' ')\n",
    "print(' ')\n",
    "n = traductor(secciones_n[i][:50], reverse_word_index)\n",
    "print(n)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(secciones[i])\n",
    "print(' ')\n",
    "text_input = nltk.tokenize.word_tokenize(secciones[i])\n",
    "print(text_input)\n",
    "match=re.search(r'(\\d+/\\d+/\\d+)',secciones[i])\n",
    "match.group(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " PLAN Y MANEJO control en 3 meses lab-psa total-rx de torax y eco abdomen total evolucion realizada por carlos alberto rodriguez grosser-fecha 22/04/21 12:43:13 \n  SPACE\nPLAN PROPN\nY CCONJ\nMANEJO PROPN\ncontrol NOUN\nen ADP\n3 NUM\nmeses NOUN\nlab-psa ADJ\ntotal-rx PROPN\nde ADP\ntorax NOUN\ny CCONJ\neco ADJ\nabdomen NOUN\ntotal ADJ\nevolucion NOUN\nrealizada ADJ\npor ADP\ncarlos NOUN\nalberto ADJ\nrodriguez NOUN\ngrosser-fecha ADJ\n22/04/21 NUM\n12:43:13 NUM\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(secciones[i])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 28.3MB/s]                    \n",
      "2021-06-10 13:49:56 INFO: Downloading default packages for language: es (Spanish)...\n",
      "2021-06-10 13:49:58 INFO: File exists: /home/felo/stanza_resources/es/default.zip.\n",
      "2021-06-10 13:50:02 INFO: Finished downloading models and saved to /home/felo/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza \n",
    "stanza.download('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-10 13:50:32 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2021-06-10 13:50:32 INFO: Use device: gpu\n",
      "2021-06-10 13:50:32 INFO: Loading: tokenize\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6fd6736befaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'es'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;31m# try to build processor, throw an exception if there is a requirements issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 self.processors[processor_name] = NAME_TO_PROCESSOR_CLASS[processor_name](config=curr_processor_config,\n\u001b[0m\u001b[1;32m    129\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                                                                                           use_gpu=self.use_gpu)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/pipeline/processor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, use_gpu)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# build the final config for the processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36m_set_up_model\u001b[0;34m(self, config, use_gpu)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_pre_tokenized_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, vocab, model_file, use_cuda)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0mnum_weights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     torch._cudnn_rnn_flatten_weight(\n\u001b[0m\u001b[1;32m    173\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' ENFERMEDAD ACTUAL pacienbte masculino de 51 años con diagnostico linfoma hodgkin clasico estadio ll ipi 3 slp a 5 años 60 secuela de isquemia a nivel de cerebelo sindrome de klippel feil `` completo 6 ciclos de quimioterapia abwd entre el 07-05-20 y el 26 -11-20 continua con dolor en hombros mejoria de parestesias y movilizacion de dedos de las manos e fisico peso 88 kg vigil buen estado general piel se observa pigmentada en la cara y antebrazos no se palpan adenopatias cardio pulmonar normal abdomen blando no doloroso sin masas ni visceromegalias extremidades sin edemas laboratorios 14-01-21 hb 13 hto 38,9 gb 5830 n 49 l 44 plaq 277.000 ca 1.2 gl 88 tg 248 ac urico 6 ct 254 pet-tc 06-01-21 al comparar con estudio previo del 28-04-20 se indetifica resolucion de adenopatias en cadena laterocervical derecha mejoria significatica de conglomerado plastron adenopatico mediastinal en la actualidad se identifican adenopatias aisladas en diferecntes niveles mediastinales descritos con leve incremento de la actividad metabolica no superando la captaicon hepatica en relacion con score 3 de los criterios de deuville de reciente aparicion adenomegalia en cadena laterocevical izquierda unica con incremento de la actividad metabolica no superando la captacion hepatica en relacion con score 5 de los critrios de deuaville comentarios paciente con linfoma hodgkin que recibe tratamiento con quimioterapia con buena tolerancia presenta pet-tc de final de tratamiento con persistencia de adenopatias en torax deuville 3 y adenopatia cervical izquierda nueva deuville 5. considero indicar tratamiento de rescate con brentuximab bendamustina se indica pregabalina tab 50 mg +60 tomar 1 cada 12 horas segun dolor ter ciclo brentuximab bendamustina dosis reducida 60 mg/m2/dia x 2 dias por ciclo peso 88 kg talla 172 50 2.02 m2 premedicacion 75.0 hosvital usuario 1045742977 responsable luis alfredo montenegro castillo telefono 3155863572 parentesco hijo hidrocortisona 200 mg ev acetaminofen 1 gr vo ondansetaon 3 mg ev difenhidramina 15 ml vo brentuximas vial 50 mg +3 aplicar 150 mg en 250 ml de ssn a pasar ev en 30 minutos dia 1 del ciclo bendamustina vial 100 mg a 4 aplicar 120 mg en 250 ml de ssn a pasar ev en 2 horas dia 1 y 2 del ciclo ciclos cada 21 dias se plantean 6 a 3 ciclos se solicita hemograma quimica serica cita control en 1 mes valoracion por dermatologia se da incapacidad por 90 dias a partir del 2 de noviembre del 2020 '"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "secciones[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "source": [
    "JJ\tAdjectives\n",
    "\n",
    "NN\tNouns\n",
    "\n",
    "RB\tAdverbs\n",
    "\n",
    "PRP\tPronouns\n",
    "\n",
    "VB\tVerbs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('ENFERMEDAD', 'NNP'),\n",
       " ('ACTUAL', 'NNP'),\n",
       " ('pacienbte', 'NN'),\n",
       " ('masculino', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('51', 'CD'),\n",
       " ('años', 'JJ'),\n",
       " ('con', 'NN'),\n",
       " ('diagnostico', 'NN'),\n",
       " ('linfoma', 'NN'),\n",
       " ('hodgkin', 'NN'),\n",
       " ('clasico', 'NN'),\n",
       " ('estadio', 'NN'),\n",
       " ('ll', 'NN'),\n",
       " ('ipi', 'NN'),\n",
       " ('3', 'CD'),\n",
       " ('slp', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('5', 'CD'),\n",
       " ('años', 'NN'),\n",
       " ('60', 'CD'),\n",
       " ('secuela', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('isquemia', 'FW'),\n",
       " ('a', 'DT'),\n",
       " ('nivel', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('cerebelo', 'FW'),\n",
       " ('sindrome', 'FW'),\n",
       " ('de', 'FW'),\n",
       " ('klippel', 'FW'),\n",
       " ('feil', 'FW'),\n",
       " ('``', '``'),\n",
       " ('completo', 'NN'),\n",
       " ('6', 'CD'),\n",
       " ('ciclos', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('quimioterapia', 'FW'),\n",
       " ('abwd', 'FW'),\n",
       " ('entre', 'FW'),\n",
       " ('el', 'FW'),\n",
       " ('07-05-20', 'JJ'),\n",
       " ('y', 'NN'),\n",
       " ('el', 'VBZ'),\n",
       " ('26', 'CD'),\n",
       " ('-11-20', 'NN'),\n",
       " ('continua', 'NN'),\n",
       " ('con', 'NN'),\n",
       " ('dolor', 'NN'),\n",
       " ('en', 'IN'),\n",
       " ('hombros', 'JJ'),\n",
       " ('mejoria', 'FW'),\n",
       " ('de', 'FW'),\n",
       " ('parestesias', 'FW'),\n",
       " ('y', 'FW'),\n",
       " ('movilizacion', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('dedos', 'FW'),\n",
       " ('de', 'FW'),\n",
       " ('las', 'FW'),\n",
       " ('manos', 'FW'),\n",
       " ('e', 'FW'),\n",
       " ('fisico', 'VBP'),\n",
       " ('peso', '$'),\n",
       " ('88', 'CD'),\n",
       " ('kg', 'NN'),\n",
       " ('vigil', 'NN'),\n",
       " ('buen', 'NN'),\n",
       " ('estado', 'VBZ'),\n",
       " ('general', 'JJ'),\n",
       " ('piel', 'NN'),\n",
       " ('se', 'NN'),\n",
       " ('observa', 'IN'),\n",
       " ('pigmentada', 'NN'),\n",
       " ('en', 'FW'),\n",
       " ('la', 'FW'),\n",
       " ('cara', 'FW'),\n",
       " ('y', 'FW'),\n",
       " ('antebrazos', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('se', 'NN'),\n",
       " ('palpan', 'NN'),\n",
       " ('adenopatias', 'VBP'),\n",
       " ('cardio', 'JJ'),\n",
       " ('pulmonar', 'NN'),\n",
       " ('normal', 'JJ'),\n",
       " ('abdomen', 'NNS'),\n",
       " ('blando', 'VBP'),\n",
       " ('no', 'DT'),\n",
       " ('doloroso', 'NN'),\n",
       " ('sin', 'NN'),\n",
       " ('masas', 'NN'),\n",
       " ('ni', 'JJ'),\n",
       " ('visceromegalias', 'NN'),\n",
       " ('extremidades', 'NNS'),\n",
       " ('sin', 'VBP'),\n",
       " ('edemas', 'JJ'),\n",
       " ('laboratorios', 'NNS'),\n",
       " ('14-01-21', 'JJ'),\n",
       " ('hb', 'NN'),\n",
       " ('13', 'CD'),\n",
       " ('hto', 'NN'),\n",
       " ('38,9', 'CD'),\n",
       " ('gb', 'NN'),\n",
       " ('5830', 'CD'),\n",
       " ('n', 'NN'),\n",
       " ('49', 'CD'),\n",
       " ('l', 'NN'),\n",
       " ('44', 'CD'),\n",
       " ('plaq', 'NN'),\n",
       " ('277.000', 'CD'),\n",
       " ('ca', 'MD'),\n",
       " ('1.2', 'CD'),\n",
       " ('gl', 'NN'),\n",
       " ('88', 'CD'),\n",
       " ('tg', 'NN'),\n",
       " ('248', 'CD'),\n",
       " ('ac', 'NN'),\n",
       " ('urico', 'JJ'),\n",
       " ('6', 'CD'),\n",
       " ('ct', 'JJ'),\n",
       " ('254', 'CD'),\n",
       " ('pet-tc', 'JJ'),\n",
       " ('06-01-21', 'JJ'),\n",
       " ('al', 'NN'),\n",
       " ('comparar', 'NN'),\n",
       " ('con', 'NN'),\n",
       " ('estudio', 'NN'),\n",
       " ('previo', 'NN'),\n",
       " ('del', 'VBZ'),\n",
       " ('28-04-20', 'JJ'),\n",
       " ('se', 'NN'),\n",
       " ('indetifica', 'JJ'),\n",
       " ('resolucion', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('adenopatias', 'FW'),\n",
       " ('en', 'FW'),\n",
       " ('cadena', 'FW'),\n",
       " ('laterocervical', 'JJ'),\n",
       " ('derecha', 'NN'),\n",
       " ('mejoria', 'NN'),\n",
       " ('significatica', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('conglomerado', 'FW'),\n",
       " ('plastron', 'NN'),\n",
       " ('adenopatico', 'VBP'),\n",
       " ('mediastinal', 'JJ'),\n",
       " ('en', 'NN'),\n",
       " ('la', 'NN'),\n",
       " ('actualidad', 'FW'),\n",
       " ('se', 'JJ'),\n",
       " ('identifican', 'JJ'),\n",
       " ('adenopatias', 'NN'),\n",
       " ('aisladas', 'NNS'),\n",
       " ('en', 'VBP'),\n",
       " ('diferecntes', 'VBZ'),\n",
       " ('niveles', 'NNS'),\n",
       " ('mediastinales', 'NNS'),\n",
       " ('descritos', 'VBP'),\n",
       " ('con', 'NN'),\n",
       " ('leve', 'VBP'),\n",
       " ('incremento', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('la', 'FW'),\n",
       " ('actividad', 'FW'),\n",
       " ('metabolica', 'FW'),\n",
       " ('no', 'DT'),\n",
       " ('superando', 'NN'),\n",
       " ('la', 'VBZ'),\n",
       " ('captaicon', 'NN'),\n",
       " ('hepatica', 'NN'),\n",
       " ('en', 'IN'),\n",
       " ('relacion', 'NN'),\n",
       " ('con', 'NN'),\n",
       " ('score', 'VBD'),\n",
       " ('3', 'CD'),\n",
       " ('de', 'IN'),\n",
       " ('los', 'FW'),\n",
       " ('criterios', 'NNS'),\n",
       " ('de', 'FW'),\n",
       " ('deuville', 'FW'),\n",
       " ('de', 'FW'),\n",
       " ('reciente', 'FW'),\n",
       " ('aparicion', 'NN'),\n",
       " ('adenomegalia', 'IN'),\n",
       " ('en', 'FW'),\n",
       " ('cadena', 'JJ'),\n",
       " ('laterocevical', 'JJ'),\n",
       " ('izquierda', 'NN'),\n",
       " ('unica', 'JJ'),\n",
       " ('con', 'NN'),\n",
       " ('incremento', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('la', 'FW'),\n",
       " ('actividad', 'FW'),\n",
       " ('metabolica', 'FW'),\n",
       " ('no', 'DT'),\n",
       " ('superando', 'NN'),\n",
       " ('la', 'VBZ'),\n",
       " ('captacion', 'NN'),\n",
       " ('hepatica', 'NN'),\n",
       " ('en', 'IN'),\n",
       " ('relacion', 'NN'),\n",
       " ('con', 'NN'),\n",
       " ('score', 'VBD'),\n",
       " ('5', 'CD'),\n",
       " ('de', 'IN'),\n",
       " ('los', 'FW'),\n",
       " ('critrios', 'NNS'),\n",
       " ('de', 'FW'),\n",
       " ('deuaville', 'FW'),\n",
       " ('comentarios', 'NNS'),\n",
       " ('paciente', 'VBP'),\n",
       " ('con', 'NN'),\n",
       " ('linfoma', 'NN'),\n",
       " ('hodgkin', 'NN'),\n",
       " ('que', 'NN'),\n",
       " ('recibe', 'NN'),\n",
       " ('tratamiento', 'IN'),\n",
       " ('con', 'NN'),\n",
       " ('quimioterapia', 'NN'),\n",
       " ('con', 'NN'),\n",
       " ('buena', 'NN'),\n",
       " ('tolerancia', 'NN'),\n",
       " ('presenta', 'JJ'),\n",
       " ('pet-tc', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('final', 'JJ'),\n",
       " ('de', 'FW'),\n",
       " ('tratamiento', 'FW'),\n",
       " ('con', 'NN'),\n",
       " ('persistencia', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('adenopatias', 'FW'),\n",
       " ('en', 'FW'),\n",
       " ('torax', 'NN'),\n",
       " ('deuville', 'VBZ'),\n",
       " ('3', 'CD'),\n",
       " ('y', 'NN'),\n",
       " ('adenopatia', 'JJ'),\n",
       " ('cervical', 'JJ'),\n",
       " ('izquierda', 'NN'),\n",
       " ('nueva', 'NN'),\n",
       " ('deuville', 'VBZ'),\n",
       " ('5.', 'CD'),\n",
       " ('considero', 'NN'),\n",
       " ('indicar', 'NN'),\n",
       " ('tratamiento', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('rescate', 'FW'),\n",
       " ('con', 'NN'),\n",
       " ('brentuximab', 'NN'),\n",
       " ('bendamustina', 'NN'),\n",
       " ('se', 'NN'),\n",
       " ('indica', 'NN'),\n",
       " ('pregabalina', 'VBP'),\n",
       " ('tab', 'NN'),\n",
       " ('50', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('+60', 'NNP'),\n",
       " ('tomar', 'NN'),\n",
       " ('1', 'CD'),\n",
       " ('cada', 'NN'),\n",
       " ('12', 'CD'),\n",
       " ('horas', 'NNS'),\n",
       " ('segun', 'JJ'),\n",
       " ('dolor', 'NN'),\n",
       " ('ter', 'NN'),\n",
       " ('ciclo', 'NN'),\n",
       " ('brentuximab', 'NN'),\n",
       " ('bendamustina', 'NN'),\n",
       " ('dosis', 'NN'),\n",
       " ('reducida', 'VBD'),\n",
       " ('60', 'CD'),\n",
       " ('mg/m2/dia', 'NN'),\n",
       " ('x', 'NN'),\n",
       " ('2', 'CD'),\n",
       " ('dias', 'JJ'),\n",
       " ('por', 'NN'),\n",
       " ('ciclo', 'NN'),\n",
       " ('peso', 'NN'),\n",
       " ('88', 'CD'),\n",
       " ('kg', 'NN'),\n",
       " ('talla', 'NN'),\n",
       " ('172', 'CD'),\n",
       " ('50', 'CD'),\n",
       " ('2.02', 'CD'),\n",
       " ('m2', 'NN'),\n",
       " ('premedicacion', 'NN'),\n",
       " ('75.0', 'CD'),\n",
       " ('hosvital', 'JJ'),\n",
       " ('usuario', 'NN'),\n",
       " ('1045742977', 'CD'),\n",
       " ('responsable', 'JJ'),\n",
       " ('luis', 'NN'),\n",
       " ('alfredo', 'NN'),\n",
       " ('montenegro', 'NN'),\n",
       " ('castillo', 'NN'),\n",
       " ('telefono', 'VBD'),\n",
       " ('3155863572', 'CD'),\n",
       " ('parentesco', 'NN'),\n",
       " ('hijo', 'NN'),\n",
       " ('hidrocortisona', 'VBD'),\n",
       " ('200', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('ev', 'NN'),\n",
       " ('acetaminofen', 'VBD'),\n",
       " ('1', 'CD'),\n",
       " ('gr', 'NN'),\n",
       " ('vo', 'NN'),\n",
       " ('ondansetaon', 'VBD'),\n",
       " ('3', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('ev', 'NN'),\n",
       " ('difenhidramina', 'VBZ'),\n",
       " ('15', 'CD'),\n",
       " ('ml', 'NN'),\n",
       " ('vo', 'NN'),\n",
       " ('brentuximas', 'VBP'),\n",
       " ('vial', 'JJ'),\n",
       " ('50', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('+3', 'NN'),\n",
       " ('aplicar', 'NN'),\n",
       " ('150', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('en', 'FW'),\n",
       " ('250', 'CD'),\n",
       " ('ml', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('ssn', 'FW'),\n",
       " ('a', 'DT'),\n",
       " ('pasar', 'NN'),\n",
       " ('ev', 'NN'),\n",
       " ('en', 'IN'),\n",
       " ('30', 'CD'),\n",
       " ('minutos', 'NNS'),\n",
       " ('dia', 'RB'),\n",
       " ('1', 'CD'),\n",
       " ('del', 'NN'),\n",
       " ('ciclo', 'NN'),\n",
       " ('bendamustina', 'VBP'),\n",
       " ('vial', 'JJ'),\n",
       " ('100', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('4', 'CD'),\n",
       " ('aplicar', 'NN'),\n",
       " ('120', 'CD'),\n",
       " ('mg', 'NN'),\n",
       " ('en', 'FW'),\n",
       " ('250', 'CD'),\n",
       " ('ml', 'NN'),\n",
       " ('de', 'FW'),\n",
       " ('ssn', 'FW'),\n",
       " ('a', 'DT'),\n",
       " ('pasar', 'NN'),\n",
       " ('ev', 'NN'),\n",
       " ('en', 'IN'),\n",
       " ('2', 'CD'),\n",
       " ('horas', 'NNS'),\n",
       " ('dia', 'RB'),\n",
       " ('1', 'CD'),\n",
       " ('y', 'JJ'),\n",
       " ('2', 'CD'),\n",
       " ('del', 'NN'),\n",
       " ('ciclo', 'NN'),\n",
       " ('ciclos', 'NN'),\n",
       " ('cada', 'VBD'),\n",
       " ('21', 'CD'),\n",
       " ('dias', 'NNS'),\n",
       " ('se', 'JJ'),\n",
       " ('plantean', 'JJ'),\n",
       " ('6', 'CD'),\n",
       " ('a', 'DT'),\n",
       " ('3', 'CD'),\n",
       " ('ciclos', 'NN'),\n",
       " ('se', 'NN'),\n",
       " ('solicita', 'JJ'),\n",
       " ('hemograma', 'NN'),\n",
       " ('quimica', 'NN'),\n",
       " ('serica', 'VBZ'),\n",
       " ('cita', 'JJ'),\n",
       " ('control', 'NN'),\n",
       " ('en', 'VBZ'),\n",
       " ('1', 'CD'),\n",
       " ('mes', 'NNS'),\n",
       " ('valoracion', 'NN'),\n",
       " ('por', 'NN'),\n",
       " ('dermatologia', 'NN'),\n",
       " ('se', 'NN'),\n",
       " ('da', 'NN'),\n",
       " ('incapacidad', 'NN'),\n",
       " ('por', 'NN'),\n",
       " ('90', 'CD'),\n",
       " ('dias', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('partir', 'NN'),\n",
       " ('del', 'NN'),\n",
       " ('2', 'CD'),\n",
       " ('de', 'IN'),\n",
       " ('noviembre', 'FW'),\n",
       " ('del', 'NN'),\n",
       " ('2020', 'CD')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "words =  word_tokenize(secciones[2])\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29688"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "len(super_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}